<!DOCTYPE html>

<html lang="en" data-content_root="../../">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>20. Intel Trust Domain Extensions (TDX) &#8212; The Linux Kernel  documentation</title>
    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="../../_static/alabaster.css?v=3918102e" />
    <script src="../../_static/documentation_options.js?v=5929fcd5"></script>
    <script src="../../_static/doctools.js?v=9a2dae69"></script>
    <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="21. Page Table Isolation (PTI)" href="pti.html" />
    <link rel="prev" title="19. AMD HSMP interface" href="amd_hsmp.html" />
   
  <link rel="stylesheet" href="../../_static/custom.css" type="text/css" />
  

  
  

  </head><body>
  <div class="document">
    
      <div class="sphinxsidebar" role="navigation" aria-label="Main">
        <div class="sphinxsidebarwrapper">
            <p class="logo"><a href="../../index.html">
              <img class="logo" src="../../_static/logo.svg" alt="Logo of The Linux Kernel"/>
            </a></p>
<h1 class="logo"><a href="../../index.html">The Linux Kernel</a></h1>



<p class="blurb">6.12.0</p>







<search id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</search>
<script>document.getElementById('searchbox').style.display = "block"</script><!-- SPDX-License-Identifier: GPL-2.0 -->

<p>
<h3 class="kernel-toc-contents">Contents</h3>
<input type="checkbox" class="kernel-toc-toggle" id = "kernel-toc-toggle" checked>
<label class="kernel-toc-title" for="kernel-toc-toggle"></label>

<div class="kerneltoc" id="kerneltoc">
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../process/development-process.html">Development process</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../process/submitting-patches.html">Submitting patches</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../process/code-of-conduct.html">Code of conduct</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../maintainer/index.html">Maintainer handbook</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../process/index.html">All development-process docs</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../core-api/index.html">Core API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../driver-api/index.html">Driver APIs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../subsystem-apis.html">Subsystems</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../locking/index.html">Locking</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../process/license-rules.html">Licensing rules</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../doc-guide/index.html">Writing documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../dev-tools/index.html">Development tools</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../dev-tools/testing-overview.html">Testing guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../kernel-hacking/index.html">Hacking guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../trace/index.html">Tracing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../fault-injection/index.html">Fault injection</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../livepatch/index.html">Livepatching</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../rust/index.html">Rust</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../admin-guide/index.html">Administration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../kbuild/index.html">Build system</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../admin-guide/reporting-issues.html">Reporting issues</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../tools/index.html">Userspace tools</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../userspace-api/index.html">Userspace API</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../firmware-guide/index.html">Firmware</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../devicetree/index.html">Firmware and Devicetree</a></li>
</ul>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="../index.html">CPU architectures</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../arc/index.html">ARC architecture</a></li>
<li class="toctree-l2"><a class="reference internal" href="../arm/index.html">ARM Architecture</a></li>
<li class="toctree-l2"><a class="reference internal" href="../arm64/index.html">ARM64 Architecture</a></li>
<li class="toctree-l2"><a class="reference internal" href="../loongarch/index.html">LoongArch Architecture</a></li>
<li class="toctree-l2"><a class="reference internal" href="../m68k/index.html">m68k Architecture</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mips/index.html">MIPS-specific Documentation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../nios2/index.html">Nios II Specific Documentation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../openrisc/index.html">OpenRISC Architecture</a></li>
<li class="toctree-l2"><a class="reference internal" href="../parisc/index.html">PA-RISC Architecture</a></li>
<li class="toctree-l2"><a class="reference internal" href="../powerpc/index.html">powerpc</a></li>
<li class="toctree-l2"><a class="reference internal" href="../riscv/index.html">RISC-V architecture</a></li>
<li class="toctree-l2"><a class="reference internal" href="../s390/index.html">s390 Architecture</a></li>
<li class="toctree-l2"><a class="reference internal" href="../sh/index.html">SuperH Interfaces Guide</a></li>
<li class="toctree-l2"><a class="reference internal" href="../sparc/index.html">Sparc Architecture</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="index.html">x86-specific Documentation</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="boot.html">1. The Linux/x86 Boot Protocol</a></li>
<li class="toctree-l3"><a class="reference internal" href="booting-dt.html">2. DeviceTree Booting</a></li>
<li class="toctree-l3"><a class="reference internal" href="cpuinfo.html">3. x86 Feature Flags</a></li>
<li class="toctree-l3"><a class="reference internal" href="topology.html">4. x86 Topology</a></li>
<li class="toctree-l3"><a class="reference internal" href="exception-tables.html">5. Kernel level exception handling</a></li>
<li class="toctree-l3"><a class="reference internal" href="kernel-stacks.html">6. Kernel Stacks</a></li>
<li class="toctree-l3"><a class="reference internal" href="entry_64.html">7. Kernel Entries</a></li>
<li class="toctree-l3"><a class="reference internal" href="earlyprintk.html">8. Early Printk</a></li>
<li class="toctree-l3"><a class="reference internal" href="orc-unwinder.html">9. ORC unwinder</a></li>
<li class="toctree-l3"><a class="reference internal" href="zero-page.html">10. Zero Page</a></li>
<li class="toctree-l3"><a class="reference internal" href="tlb.html">11. The TLB</a></li>
<li class="toctree-l3"><a class="reference internal" href="mtrr.html">12. MTRR (Memory Type Range Register) control</a></li>
<li class="toctree-l3"><a class="reference internal" href="pat.html">13. PAT (Page Attribute Table)</a></li>
<li class="toctree-l3"><a class="reference internal" href="intel-hfi.html">14. Hardware-Feedback Interface for scheduling on Intel Hardware</a></li>
<li class="toctree-l3"><a class="reference internal" href="shstk.html">15. Control-flow Enforcement Technology (CET) Shadow Stack</a></li>
<li class="toctree-l3"><a class="reference internal" href="iommu.html">16. x86 IOMMU Support</a></li>
<li class="toctree-l3"><a class="reference internal" href="intel_txt.html">17. Intel(R) TXT Overview</a></li>
<li class="toctree-l3"><a class="reference internal" href="amd-memory-encryption.html">18. AMD Memory Encryption</a></li>
<li class="toctree-l3"><a class="reference internal" href="amd_hsmp.html">19. AMD HSMP interface</a></li>
<li class="toctree-l3 current"><a class="current reference internal" href="#">20. Intel Trust Domain Extensions (TDX)</a></li>
<li class="toctree-l3"><a class="reference internal" href="pti.html">21. Page Table Isolation (PTI)</a></li>
<li class="toctree-l3"><a class="reference internal" href="mds.html">22. Microarchitectural Data Sampling (MDS) mitigation</a></li>
<li class="toctree-l3"><a class="reference internal" href="microcode.html">23. The Linux Microcode Loader</a></li>
<li class="toctree-l3"><a class="reference internal" href="resctrl.html">24. User Interface for Resource Control feature</a></li>
<li class="toctree-l3"><a class="reference internal" href="tsx_async_abort.html">25. TSX Async Abort (TAA) mitigation</a></li>
<li class="toctree-l3"><a class="reference internal" href="buslock.html">26. Bus lock detection and handling</a></li>
<li class="toctree-l3"><a class="reference internal" href="usb-legacy-support.html">27. USB Legacy support</a></li>
<li class="toctree-l3"><a class="reference internal" href="i386/index.html">28. i386 Support</a></li>
<li class="toctree-l3"><a class="reference internal" href="x86_64/index.html">29. x86_64 Support</a></li>
<li class="toctree-l3"><a class="reference internal" href="ifs.html">30. In-Field Scan</a></li>
<li class="toctree-l3"><a class="reference internal" href="sva.html">31. Shared Virtual Addressing (SVA) with ENQCMD</a></li>
<li class="toctree-l3"><a class="reference internal" href="sgx.html">32. Software Guard eXtensions (SGX)</a></li>
<li class="toctree-l3"><a class="reference internal" href="features.html">33. Feature status on x86 architecture</a></li>
<li class="toctree-l3"><a class="reference internal" href="elf_auxvec.html">34. x86-specific ELF Auxiliary Vectors</a></li>
<li class="toctree-l3"><a class="reference internal" href="xstate.html">35. Using XSTATE features in user space applications</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../xtensa/index.html">Xtensa Architecture</a></li>
</ul>
</li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../staging/index.html">Unsorted documentation</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../translations/index.html">Translations</a></li>
</ul>

</div>

<script type="text/javascript"> <!--
  var sbar = document.getElementsByClassName("sphinxsidebar")[0];
  let currents = document.getElementsByClassName("current")
  if (currents.length) {
    sbar.scrollTop = currents[currents.length - 1].offsetTop;
  }
  --> </script>
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="../../_sources/arch/x86/tdx.rst.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div>
        </div>
      </div>
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <!-- SPDX-License-Identifier: GPL-2.0 -->
<!-- Copyright © 2023, Oracle and/or its affiliates. -->


<section id="intel-trust-domain-extensions-tdx">
<h1><span class="section-number">20. </span>Intel Trust Domain Extensions (TDX)<a class="headerlink" href="#intel-trust-domain-extensions-tdx" title="Link to this heading">¶</a></h1>
<p>Intel’s Trust Domain Extensions (TDX) protect confidential guest VMs from
the host and physical attacks by isolating the guest register state and by
encrypting the guest memory. In TDX, a special module running in a special
mode sits between the host and the guest and manages the guest/host
separation.</p>
<section id="tdx-host-kernel-support">
<h2><span class="section-number">20.1. </span>TDX Host Kernel Support<a class="headerlink" href="#tdx-host-kernel-support" title="Link to this heading">¶</a></h2>
<p>TDX introduces a new CPU mode called Secure Arbitration Mode (SEAM) and
a new isolated range pointed by the SEAM Ranger Register (SEAMRR).  A
CPU-attested software module called ‘the TDX module’ runs inside the new
isolated range to provide the functionalities to manage and run protected
VMs.</p>
<p>TDX also leverages Intel Multi-Key Total Memory Encryption (MKTME) to
provide crypto-protection to the VMs.  TDX reserves part of MKTME KeyIDs
as TDX private KeyIDs, which are only accessible within the SEAM mode.
BIOS is responsible for partitioning legacy MKTME KeyIDs and TDX KeyIDs.</p>
<p>Before the TDX module can be used to create and run protected VMs, it
must be loaded into the isolated range and properly initialized.  The TDX
architecture doesn’t require the BIOS to load the TDX module, but the
kernel assumes it is loaded by the BIOS.</p>
<section id="tdx-boot-time-detection">
<h3><span class="section-number">20.1.1. </span>TDX boot-time detection<a class="headerlink" href="#tdx-boot-time-detection" title="Link to this heading">¶</a></h3>
<p>The kernel detects TDX by detecting TDX private KeyIDs during kernel
boot.  Below dmesg shows when TDX is enabled by BIOS:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>[..] virt/tdx: BIOS enabled: private KeyID range: [16, 64)
</pre></div>
</div>
</section>
<section id="tdx-module-initialization">
<h3><span class="section-number">20.1.2. </span>TDX module initialization<a class="headerlink" href="#tdx-module-initialization" title="Link to this heading">¶</a></h3>
<p>The kernel talks to the TDX module via the new SEAMCALL instruction.  The
TDX module implements SEAMCALL leaf functions to allow the kernel to
initialize it.</p>
<p>If the TDX module isn’t loaded, the SEAMCALL instruction fails with a
special error.  In this case the kernel fails the module initialization
and reports the module isn’t loaded:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>[..] virt/tdx: module not loaded
</pre></div>
</div>
<p>Initializing the TDX module consumes roughly ~1/256th system RAM size to
use it as ‘metadata’ for the TDX memory.  It also takes additional CPU
time to initialize those metadata along with the TDX module itself.  Both
are not trivial.  The kernel initializes the TDX module at runtime on
demand.</p>
<p>Besides initializing the TDX module, a per-cpu initialization SEAMCALL
must be done on one cpu before any other SEAMCALLs can be made on that
cpu.</p>
<p>The kernel provides two functions, tdx_enable() and tdx_cpu_enable() to
allow the user of TDX to enable the TDX module and enable TDX on local
cpu respectively.</p>
<p>Making SEAMCALL requires VMXON has been done on that CPU.  Currently only
KVM implements VMXON.  For now both tdx_enable() and tdx_cpu_enable()
don’t do VMXON internally (not trivial), but depends on the caller to
guarantee that.</p>
<p>To enable TDX, the caller of TDX should: 1) temporarily disable CPU
hotplug; 2) do VMXON and tdx_enable_cpu() on all online cpus; 3) call
tdx_enable().  For example:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>cpus_read_lock();
on_each_cpu(vmxon_and_tdx_cpu_enable());
ret = tdx_enable();
cpus_read_unlock();
if (ret)
        goto no_tdx;
// TDX is ready to use
</pre></div>
</div>
<p>And the caller of TDX must guarantee the tdx_cpu_enable() has been
successfully done on any cpu before it wants to run any other SEAMCALL.
A typical usage is do both VMXON and tdx_cpu_enable() in CPU hotplug
online callback, and refuse to online if tdx_cpu_enable() fails.</p>
<p>User can consult dmesg to see whether the TDX module has been initialized.</p>
<p>If the TDX module is initialized successfully, dmesg shows something
like below:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>[..] virt/tdx: 262668 KBs allocated for PAMT
[..] virt/tdx: module initialized
</pre></div>
</div>
<p>If the TDX module failed to initialize, dmesg also shows it failed to
initialize:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>[..] virt/tdx: module initialization failed ...
</pre></div>
</div>
</section>
<section id="tdx-interaction-to-other-kernel-components">
<h3><span class="section-number">20.1.3. </span>TDX Interaction to Other Kernel Components<a class="headerlink" href="#tdx-interaction-to-other-kernel-components" title="Link to this heading">¶</a></h3>
<section id="tdx-memory-policy">
<h4><span class="section-number">20.1.3.1. </span>TDX Memory Policy<a class="headerlink" href="#tdx-memory-policy" title="Link to this heading">¶</a></h4>
<p>TDX reports a list of “Convertible Memory Region” (CMR) to tell the
kernel which memory is TDX compatible.  The kernel needs to build a list
of memory regions (out of CMRs) as “TDX-usable” memory and pass those
regions to the TDX module.  Once this is done, those “TDX-usable” memory
regions are fixed during module’s lifetime.</p>
<p>To keep things simple, currently the kernel simply guarantees all pages
in the page allocator are TDX memory.  Specifically, the kernel uses all
system memory in the core-mm “at the time of TDX module initialization”
as TDX memory, and in the meantime, refuses to online any non-TDX-memory
in the memory hotplug.</p>
</section>
<section id="physical-memory-hotplug">
<h4><span class="section-number">20.1.3.2. </span>Physical Memory Hotplug<a class="headerlink" href="#physical-memory-hotplug" title="Link to this heading">¶</a></h4>
<p>Note TDX assumes convertible memory is always physically present during
machine’s runtime.  A non-buggy BIOS should never support hot-removal of
any convertible memory.  This implementation doesn’t handle ACPI memory
removal but depends on the BIOS to behave correctly.</p>
</section>
<section id="cpu-hotplug">
<h4><span class="section-number">20.1.3.3. </span>CPU Hotplug<a class="headerlink" href="#cpu-hotplug" title="Link to this heading">¶</a></h4>
<p>TDX module requires the per-cpu initialization SEAMCALL must be done on
one cpu before any other SEAMCALLs can be made on that cpu.  The kernel
provides tdx_cpu_enable() to let the user of TDX to do it when the user
wants to use a new cpu for TDX task.</p>
<p>TDX doesn’t support physical (ACPI) CPU hotplug.  During machine boot,
TDX verifies all boot-time present logical CPUs are TDX compatible before
enabling TDX.  A non-buggy BIOS should never support hot-add/removal of
physical CPU.  Currently the kernel doesn’t handle physical CPU hotplug,
but depends on the BIOS to behave correctly.</p>
<p>Note TDX works with CPU logical online/offline, thus the kernel still
allows to offline logical CPU and online it again.</p>
</section>
<section id="kexec">
<h4><span class="section-number">20.1.3.4. </span>Kexec()<a class="headerlink" href="#kexec" title="Link to this heading">¶</a></h4>
<p>TDX host support currently lacks the ability to handle kexec.  For
simplicity only one of them can be enabled in the Kconfig.  This will be
fixed in the future.</p>
</section>
<section id="erratum">
<h4><span class="section-number">20.1.3.5. </span>Erratum<a class="headerlink" href="#erratum" title="Link to this heading">¶</a></h4>
<p>The first few generations of TDX hardware have an erratum.  A partial
write to a TDX private memory cacheline will silently “poison” the
line.  Subsequent reads will consume the poison and generate a machine
check.</p>
<p>A partial write is a memory write where a write transaction of less than
cacheline lands at the memory controller.  The CPU does these via
non-temporal write instructions (like MOVNTI), or through UC/WC memory
mappings.  Devices can also do partial writes via DMA.</p>
<p>Theoretically, a kernel bug could do partial write to TDX private memory
and trigger unexpected machine check.  What’s more, the machine check
code will present these as “Hardware error” when they were, in fact, a
software-triggered issue.  But in the end, this issue is hard to trigger.</p>
<p>If the platform has such erratum, the kernel prints additional message in
machine check handler to tell user the machine check may be caused by
kernel bug on TDX private memory.</p>
</section>
<section id="interaction-vs-s3-and-deeper-states">
<h4><span class="section-number">20.1.3.6. </span>Interaction vs S3 and deeper states<a class="headerlink" href="#interaction-vs-s3-and-deeper-states" title="Link to this heading">¶</a></h4>
<p>TDX cannot survive from S3 and deeper states.  The hardware resets and
disables TDX completely when platform goes to S3 and deeper.  Both TDX
guests and the TDX module get destroyed permanently.</p>
<p>The kernel uses S3 for suspend-to-ram, and use S4 and deeper states for
hibernation.  Currently, for simplicity, the kernel chooses to make TDX
mutually exclusive with S3 and hibernation.</p>
<p>The kernel disables TDX during early boot when hibernation support is
available:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>[..] virt/tdx: initialization failed: Hibernation support is enabled
</pre></div>
</div>
<p>Add ‘nohibernate’ kernel command line to disable hibernation in order to
use TDX.</p>
<p>ACPI S3 is disabled during kernel early boot if TDX is enabled.  The user
needs to turn off TDX in the BIOS in order to use S3.</p>
</section>
</section>
</section>
<section id="tdx-guest-support">
<h2><span class="section-number">20.2. </span>TDX Guest Support<a class="headerlink" href="#tdx-guest-support" title="Link to this heading">¶</a></h2>
<p>Since the host cannot directly access guest registers or memory, much
normal functionality of a hypervisor must be moved into the guest. This is
implemented using a Virtualization Exception (#VE) that is handled by the
guest kernel. A #VE is handled entirely inside the guest kernel, but some
require the hypervisor to be consulted.</p>
<p>TDX includes new hypercall-like mechanisms for communicating from the
guest to the hypervisor or the TDX module.</p>
<section id="new-tdx-exceptions">
<h3><span class="section-number">20.2.1. </span>New TDX Exceptions<a class="headerlink" href="#new-tdx-exceptions" title="Link to this heading">¶</a></h3>
<p>TDX guests behave differently from bare-metal and traditional VMX guests.
In TDX guests, otherwise normal instructions or memory accesses can cause
#VE or #GP exceptions.</p>
<p>Instructions marked with an ‘*’ conditionally cause exceptions.  The
details for these instructions are discussed below.</p>
<section id="instruction-based-ve">
<h4><span class="section-number">20.2.1.1. </span>Instruction-based #VE<a class="headerlink" href="#instruction-based-ve" title="Link to this heading">¶</a></h4>
<ul class="simple">
<li><p>Port I/O (INS, OUTS, IN, OUT)</p></li>
<li><p>HLT</p></li>
<li><p>MONITOR, MWAIT</p></li>
<li><p>WBINVD, INVD</p></li>
<li><p>VMCALL</p></li>
<li><p>RDMSR*,WRMSR*</p></li>
<li><p>CPUID*</p></li>
</ul>
</section>
<section id="instruction-based-gp">
<h4><span class="section-number">20.2.1.2. </span>Instruction-based #GP<a class="headerlink" href="#instruction-based-gp" title="Link to this heading">¶</a></h4>
<ul class="simple">
<li><p>All VMX instructions: INVEPT, INVVPID, VMCLEAR, VMFUNC, VMLAUNCH,
VMPTRLD, VMPTRST, VMREAD, VMRESUME, VMWRITE, VMXOFF, VMXON</p></li>
<li><p>ENCLS, ENCLU</p></li>
<li><p>GETSEC</p></li>
<li><p>RSM</p></li>
<li><p>ENQCMD</p></li>
<li><p>RDMSR*,WRMSR*</p></li>
</ul>
</section>
<section id="rdmsr-wrmsr-behavior">
<h4><span class="section-number">20.2.1.3. </span>RDMSR/WRMSR Behavior<a class="headerlink" href="#rdmsr-wrmsr-behavior" title="Link to this heading">¶</a></h4>
<p>MSR access behavior falls into three categories:</p>
<ul class="simple">
<li><p>#GP generated</p></li>
<li><p>#VE generated</p></li>
<li><p>“Just works”</p></li>
</ul>
<p>In general, the #GP MSRs should not be used in guests.  Their use likely
indicates a bug in the guest.  The guest may try to handle the #GP with a
hypercall but it is unlikely to succeed.</p>
<p>The #VE MSRs are typically able to be handled by the hypervisor.  Guests
can make a hypercall to the hypervisor to handle the #VE.</p>
<p>The “just works” MSRs do not need any special guest handling.  They might
be implemented by directly passing through the MSR to the hardware or by
trapping and handling in the TDX module.  Other than possibly being slow,
these MSRs appear to function just as they would on bare metal.</p>
</section>
<section id="cpuid-behavior">
<h4><span class="section-number">20.2.1.4. </span>CPUID Behavior<a class="headerlink" href="#cpuid-behavior" title="Link to this heading">¶</a></h4>
<p>For some CPUID leaves and sub-leaves, the virtualized bit fields of CPUID
return values (in guest EAX/EBX/ECX/EDX) are configurable by the
hypervisor. For such cases, the Intel TDX module architecture defines two
virtualization types:</p>
<ul class="simple">
<li><p>Bit fields for which the hypervisor controls the value seen by the guest
TD.</p></li>
<li><p>Bit fields for which the hypervisor configures the value such that the
guest TD either sees their native value or a value of 0.  For these bit
fields, the hypervisor can mask off the native values, but it can not
turn <em>on</em> values.</p></li>
</ul>
<p>A #VE is generated for CPUID leaves and sub-leaves that the TDX module does
not know how to handle. The guest kernel may ask the hypervisor for the
value with a hypercall.</p>
</section>
</section>
<section id="ve-on-memory-accesses">
<h3><span class="section-number">20.2.2. </span>#VE on Memory Accesses<a class="headerlink" href="#ve-on-memory-accesses" title="Link to this heading">¶</a></h3>
<p>There are essentially two classes of TDX memory: private and shared.
Private memory receives full TDX protections.  Its content is protected
against access from the hypervisor.  Shared memory is expected to be
shared between guest and hypervisor and does not receive full TDX
protections.</p>
<p>A TD guest is in control of whether its memory accesses are treated as
private or shared.  It selects the behavior with a bit in its page table
entries.  This helps ensure that a guest does not place sensitive
information in shared memory, exposing it to the untrusted hypervisor.</p>
<section id="ve-on-shared-memory">
<h4><span class="section-number">20.2.2.1. </span>#VE on Shared Memory<a class="headerlink" href="#ve-on-shared-memory" title="Link to this heading">¶</a></h4>
<p>Access to shared mappings can cause a #VE.  The hypervisor ultimately
controls whether a shared memory access causes a #VE, so the guest must be
careful to only reference shared pages it can safely handle a #VE.  For
instance, the guest should be careful not to access shared memory in the
#VE handler before it reads the #VE info structure (TDG.VP.VEINFO.GET).</p>
<p>Shared mapping content is entirely controlled by the hypervisor. The guest
should only use shared mappings for communicating with the hypervisor.
Shared mappings must never be used for sensitive memory content like kernel
stacks.  A good rule of thumb is that hypervisor-shared memory should be
treated the same as memory mapped to userspace.  Both the hypervisor and
userspace are completely untrusted.</p>
<p>MMIO for virtual devices is implemented as shared memory.  The guest must
be careful not to access device MMIO regions unless it is also prepared to
handle a #VE.</p>
</section>
<section id="ve-on-private-pages">
<h4><span class="section-number">20.2.2.2. </span>#VE on Private Pages<a class="headerlink" href="#ve-on-private-pages" title="Link to this heading">¶</a></h4>
<p>An access to private mappings can also cause a #VE.  Since all kernel
memory is also private memory, the kernel might theoretically need to
handle a #VE on arbitrary kernel memory accesses.  This is not feasible, so
TDX guests ensure that all guest memory has been “accepted” before memory
is used by the kernel.</p>
<p>A modest amount of memory (typically 512M) is pre-accepted by the firmware
before the kernel runs to ensure that the kernel can start up without
being subjected to a #VE.</p>
<p>The hypervisor is permitted to unilaterally move accepted pages to a
“blocked” state. However, if it does this, page access will not generate a
#VE.  It will, instead, cause a “TD Exit” where the hypervisor is required
to handle the exception.</p>
</section>
</section>
<section id="linux-ve-handler">
<h3><span class="section-number">20.2.3. </span>Linux #VE handler<a class="headerlink" href="#linux-ve-handler" title="Link to this heading">¶</a></h3>
<p>Just like page faults or #GP’s, #VE exceptions can be either handled or be
fatal.  Typically, an unhandled userspace #VE results in a SIGSEGV.
An unhandled kernel #VE results in an oops.</p>
<p>Handling nested exceptions on x86 is typically nasty business.  A #VE
could be interrupted by an NMI which triggers another #VE and hilarity
ensues.  The TDX #VE architecture anticipated this scenario and includes a
feature to make it slightly less nasty.</p>
<p>During #VE handling, the TDX module ensures that all interrupts (including
NMIs) are blocked.  The block remains in place until the guest makes a
TDG.VP.VEINFO.GET TDCALL.  This allows the guest to control when interrupts
or a new #VE can be delivered.</p>
<p>However, the guest kernel must still be careful to avoid potential
#VE-triggering actions (discussed above) while this block is in place.
While the block is in place, any #VE is elevated to a double fault (#DF)
which is not recoverable.</p>
</section>
<section id="mmio-handling">
<h3><span class="section-number">20.2.4. </span>MMIO handling<a class="headerlink" href="#mmio-handling" title="Link to this heading">¶</a></h3>
<p>In non-TDX VMs, MMIO is usually implemented by giving a guest access to a
mapping which will cause a VMEXIT on access, and then the hypervisor
emulates the access.  That is not possible in TDX guests because VMEXIT
will expose the register state to the host. TDX guests don’t trust the host
and can’t have their state exposed to the host.</p>
<p>In TDX, MMIO regions typically trigger a #VE exception in the guest.  The
guest #VE handler then emulates the MMIO instruction inside the guest and
converts it into a controlled TDCALL to the host, rather than exposing
guest state to the host.</p>
<p>MMIO addresses on x86 are just special physical addresses. They can
theoretically be accessed with any instruction that accesses memory.
However, the kernel instruction decoding method is limited. It is only
designed to decode instructions like those generated by io.h macros.</p>
<p>MMIO access via other means (like structure overlays) may result in an
oops.</p>
</section>
<section id="shared-memory-conversions">
<h3><span class="section-number">20.2.5. </span>Shared Memory Conversions<a class="headerlink" href="#shared-memory-conversions" title="Link to this heading">¶</a></h3>
<p>All TDX guest memory starts out as private at boot.  This memory can not
be accessed by the hypervisor.  However, some kernel users like device
drivers might have a need to share data with the hypervisor.  To do this,
memory must be converted between shared and private.  This can be
accomplished using some existing memory encryption helpers:</p>
<blockquote>
<div><ul class="simple">
<li><p>set_memory_decrypted() converts a range of pages to shared.</p></li>
<li><p>set_memory_encrypted() converts memory back to private.</p></li>
</ul>
</div></blockquote>
<p>Device drivers are the primary user of shared memory, but there’s no need
to touch every driver. DMA buffers and <a class="reference internal" href="../../driver-api/device-io.html#c.ioremap" title="ioremap"><code class="xref c c-func docutils literal notranslate"><span class="pre">ioremap()</span></code></a> do the conversions
automatically.</p>
<p>TDX uses SWIOTLB for most DMA allocations. The SWIOTLB buffer is
converted to shared on boot.</p>
<p>For coherent DMA allocation, the DMA buffer gets converted on the
allocation. Check force_dma_unencrypted() for details.</p>
</section>
</section>
<section id="attestation">
<h2><span class="section-number">20.3. </span>Attestation<a class="headerlink" href="#attestation" title="Link to this heading">¶</a></h2>
<p>Attestation is used to verify the TDX guest trustworthiness to other
entities before provisioning secrets to the guest. For example, a key
server may want to use attestation to verify that the guest is the
desired one before releasing the encryption keys to mount the encrypted
rootfs or a secondary drive.</p>
<p>The TDX module records the state of the TDX guest in various stages of
the guest boot process using the build time measurement register (MRTD)
and runtime measurement registers (RTMR). Measurements related to the
guest initial configuration and firmware image are recorded in the MRTD
register. Measurements related to initial state, kernel image, firmware
image, command line options, initrd, ACPI tables, etc are recorded in
RTMR registers. For more details, as an example, please refer to TDX
Virtual Firmware design specification, section titled “TD Measurement”.
At TDX guest runtime, the attestation process is used to attest to these
measurements.</p>
<p>The attestation process consists of two steps: TDREPORT generation and
Quote generation.</p>
<p>TDX guest uses TDCALL[TDG.MR.REPORT] to get the TDREPORT (TDREPORT_STRUCT)
from the TDX module. TDREPORT is a fixed-size data structure generated by
the TDX module which contains guest-specific information (such as build
and boot measurements), platform security version, and the MAC to protect
the integrity of the TDREPORT. A user-provided 64-Byte REPORTDATA is used
as input and included in the TDREPORT. Typically it can be some nonce
provided by attestation service so the TDREPORT can be verified uniquely.
More details about the TDREPORT can be found in Intel TDX Module
specification, section titled “TDG.MR.REPORT Leaf”.</p>
<p>After getting the TDREPORT, the second step of the attestation process
is to send it to the Quoting Enclave (QE) to generate the Quote. TDREPORT
by design can only be verified on the local platform as the MAC key is
bound to the platform. To support remote verification of the TDREPORT,
TDX leverages Intel SGX Quoting Enclave to verify the TDREPORT locally
and convert it to a remotely verifiable Quote. Method of sending TDREPORT
to QE is implementation specific. Attestation software can choose
whatever communication channel available (i.e. vsock or TCP/IP) to
send the TDREPORT to QE and receive the Quote.</p>
</section>
<section id="references">
<h2><span class="section-number">20.4. </span>References<a class="headerlink" href="#references" title="Link to this heading">¶</a></h2>
<p>TDX reference material is collected here:</p>
<p><a class="reference external" href="https://www.intel.com/content/www/us/en/developer/articles/technical/intel-trust-domain-extensions.html">https://www.intel.com/content/www/us/en/developer/articles/technical/intel-trust-domain-extensions.html</a></p>
</section>
</section>


          </div>
          
        </div>
      </div>
    <div class="clearer"></div>
  </div>
    <div class="footer">
      &#169;The kernel development community.
      
      |
      Powered by <a href="https://www.sphinx-doc.org/">Sphinx 7.4.7</a>
      &amp; <a href="https://alabaster.readthedocs.io">Alabaster 0.7.16</a>
      
      |
      <a href="../../_sources/arch/x86/tdx.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>