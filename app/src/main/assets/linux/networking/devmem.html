<!DOCTYPE html>

<html lang="en" data-content_root="../">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Device Memory TCP &#8212; The Linux Kernel  documentation</title>
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="../_static/alabaster.css?v=a152c8ac" />
    <script src="../_static/documentation_options.js?v=5929fcd5"></script>
    <script src="../_static/doctools.js?v=888ff710"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="DNS Resolver Module" href="dns_resolver.html" />
    <link rel="prev" title="DCTCP (DataCenter TCP)" href="dctcp.html" />
   
  <link rel="stylesheet" href="../_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  <div class="document">
    
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
            <p class="logo"><a href="../index.html">
              <img class="logo" src="../_static/logo.svg" alt="Logo"/>
            </a></p>
<h1 class="logo"><a href="../index.html">The Linux Kernel</a></h1>



<p class="blurb">6.13.0</p>







<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>document.getElementById('searchbox').style.display = "block"</script><!-- SPDX-License-Identifier: GPL-2.0 -->

<p>
<h3 class="kernel-toc-contents">Contents</h3>
<input type="checkbox" class="kernel-toc-toggle" id = "kernel-toc-toggle" checked>
<label class="kernel-toc-title" for="kernel-toc-toggle"></label>

<div class="kerneltoc" id="kerneltoc">
<ul>
<li class="toctree-l1"><a class="reference internal" href="../process/development-process.html">Development process</a></li>
<li class="toctree-l1"><a class="reference internal" href="../process/submitting-patches.html">Submitting patches</a></li>
<li class="toctree-l1"><a class="reference internal" href="../process/code-of-conduct.html">Code of conduct</a></li>
<li class="toctree-l1"><a class="reference internal" href="../maintainer/index.html">Maintainer handbook</a></li>
<li class="toctree-l1"><a class="reference internal" href="../process/index.html">All development-process docs</a></li>
</ul>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../core-api/index.html">Core API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../driver-api/index.html">Driver APIs</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../subsystem-apis.html">Subsystems</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../subsystem-apis.html#core-subsystems">Core subsystems</a></li>
<li class="toctree-l2"><a class="reference internal" href="../subsystem-apis.html#human-interfaces">Human interfaces</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="../subsystem-apis.html#networking-interfaces">Networking interfaces</a><ul class="current">
<li class="toctree-l3 current"><a class="reference internal" href="index.html">Networking</a></li>
<li class="toctree-l3"><a class="reference internal" href="../netlabel/index.html">NetLabel</a></li>
<li class="toctree-l3"><a class="reference internal" href="../infiniband/index.html">InfiniBand</a></li>
<li class="toctree-l3"><a class="reference internal" href="../isdn/index.html">ISDN</a></li>
<li class="toctree-l3"><a class="reference internal" href="../mhi/index.html">MHI</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../subsystem-apis.html#storage-interfaces">Storage interfaces</a></li>
<li class="toctree-l2"><a class="reference internal" href="../subsystem-apis.html#other-subsystems">Other subsystems</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../locking/index.html">Locking</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../process/license-rules.html">Licensing rules</a></li>
<li class="toctree-l1"><a class="reference internal" href="../doc-guide/index.html">Writing documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../dev-tools/index.html">Development tools</a></li>
<li class="toctree-l1"><a class="reference internal" href="../dev-tools/testing-overview.html">Testing guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../kernel-hacking/index.html">Hacking guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../trace/index.html">Tracing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../fault-injection/index.html">Fault injection</a></li>
<li class="toctree-l1"><a class="reference internal" href="../livepatch/index.html">Livepatching</a></li>
<li class="toctree-l1"><a class="reference internal" href="../rust/index.html">Rust</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../admin-guide/index.html">Administration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../kbuild/index.html">Build system</a></li>
<li class="toctree-l1"><a class="reference internal" href="../admin-guide/reporting-issues.html">Reporting issues</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tools/index.html">Userspace tools</a></li>
<li class="toctree-l1"><a class="reference internal" href="../userspace-api/index.html">Userspace API</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../firmware-guide/index.html">Firmware</a></li>
<li class="toctree-l1"><a class="reference internal" href="../devicetree/index.html">Firmware and Devicetree</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../arch/index.html">CPU architectures</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../staging/index.html">Unsorted documentation</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../translations/index.html">Translations</a></li>
</ul>

</div>

<script type="text/javascript"> <!--
  var sbar = document.getElementsByClassName("sphinxsidebar")[0];
  let currents = document.getElementsByClassName("current")
  if (currents.length) {
    sbar.scrollTop = currents[currents.length - 1].offsetTop;
  }
  --> </script>
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="../_sources/networking/devmem.rst.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div>
        </div>
      </div>
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <!-- SPDX-License-Identifier: GPL-2.0 -->
<!-- Copyright © 2023, Oracle and/or its affiliates. -->


<section id="device-memory-tcp">
<h1>Device Memory TCP<a class="headerlink" href="#device-memory-tcp" title="Link to this heading">¶</a></h1>
<section id="intro">
<h2>Intro<a class="headerlink" href="#intro" title="Link to this heading">¶</a></h2>
<p>Device memory TCP (devmem TCP) enables receiving data directly into device
memory (dmabuf). The feature is currently implemented for TCP sockets.</p>
<section id="opportunity">
<h3>Opportunity<a class="headerlink" href="#opportunity" title="Link to this heading">¶</a></h3>
<p>A large number of data transfers have device memory as the source and/or
destination. Accelerators drastically increased the prevalence of such
transfers.  Some examples include:</p>
<ul class="simple">
<li><p>Distributed training, where ML accelerators, such as GPUs on different hosts,
exchange data.</p></li>
<li><p>Distributed raw block storage applications transfer large amounts of data with
remote SSDs. Much of this data does not require host processing.</p></li>
</ul>
<p>Typically the Device-to-Device data transfers in the network are implemented as
the following low-level operations: Device-to-Host copy, Host-to-Host network
transfer, and Host-to-Device copy.</p>
<p>The flow involving host copies is suboptimal, especially for bulk data transfers,
and can put significant strains on system resources such as host memory
bandwidth and PCIe bandwidth.</p>
<p>Devmem TCP optimizes this use case by implementing socket APIs that enable
the user to receive incoming network packets directly into device memory.</p>
<p>Packet payloads go directly from the NIC to device memory.</p>
<p>Packet headers go to host memory and are processed by the TCP/IP stack
normally. The NIC must support header split to achieve this.</p>
<p>Advantages:</p>
<ul class="simple">
<li><p>Alleviate host memory bandwidth pressure, compared to existing
network-transfer + device-copy semantics.</p></li>
<li><p>Alleviate PCIe bandwidth pressure, by limiting data transfer to the lowest
level of the PCIe tree, compared to the traditional path which sends data
through the root complex.</p></li>
</ul>
</section>
<section id="more-info">
<h3>More Info<a class="headerlink" href="#more-info" title="Link to this heading">¶</a></h3>
<blockquote>
<div><dl class="simple">
<dt>slides, video</dt><dd><p><a class="reference external" href="https://netdevconf.org/0x17/sessions/talk/device-memory-tcp.html">https://netdevconf.org/0x17/sessions/talk/device-memory-tcp.html</a></p>
</dd>
<dt>patchset</dt><dd><p>[PATCH net-next v24 00/13] Device Memory TCP
<a class="reference external" href="https://lore.kernel.org/netdev/20240831004313.3713467-1-almasrymina&#64;google.com/">https://lore.kernel.org/netdev/20240831004313.3713467-1-almasrymina&#64;google.com/</a></p>
</dd>
</dl>
</div></blockquote>
</section>
</section>
<section id="interface">
<h2>Interface<a class="headerlink" href="#interface" title="Link to this heading">¶</a></h2>
<section id="example">
<h3>Example<a class="headerlink" href="#example" title="Link to this heading">¶</a></h3>
<p>tools/testing/selftests/net/ncdevmem.c:do_server shows an example of setting up
the RX path of this API.</p>
</section>
<section id="nic-setup">
<h3>NIC Setup<a class="headerlink" href="#nic-setup" title="Link to this heading">¶</a></h3>
<p>Header split, flow steering, &amp; RSS are required features for devmem TCP.</p>
<p>Header split is used to split incoming packets into a header buffer in host
memory, and a payload buffer in device memory.</p>
<p>Flow steering &amp; RSS are used to ensure that only flows targeting devmem land on
an RX queue bound to devmem.</p>
<p>Enable header split &amp; flow steering:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span># enable header split
ethtool -G eth1 tcp-data-split on


# enable flow steering
ethtool -K eth1 ntuple on
</pre></div>
</div>
<p>Configure RSS to steer all traffic away from the target RX queue (queue 15 in
this example):</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>ethtool --set-rxfh-indir eth1 equal 15
</pre></div>
</div>
<p>The user must bind a dmabuf to any number of RX queues on a given NIC using
the netlink API:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>/* Bind dmabuf to NIC RX queue 15 */
struct netdev_queue *queues;
queues = malloc(sizeof(*queues) * 1);

queues[0]._present.type = 1;
queues[0]._present.idx = 1;
queues[0].type = NETDEV_RX_QUEUE_TYPE_RX;
queues[0].idx = 15;

*ys = ynl_sock_create(&amp;ynl_netdev_family, &amp;yerr);

req = netdev_bind_rx_req_alloc();
netdev_bind_rx_req_set_ifindex(req, 1 /* ifindex */);
netdev_bind_rx_req_set_dmabuf_fd(req, dmabuf_fd);
__netdev_bind_rx_req_set_queues(req, queues, n_queue_index);

rsp = netdev_bind_rx(*ys, req);

dmabuf_id = rsp-&gt;dmabuf_id;
</pre></div>
</div>
<p>The netlink API returns a dmabuf_id: a unique ID that refers to this dmabuf
that has been bound.</p>
<p>The user can unbind the dmabuf from the netdevice by closing the netlink socket
that established the binding. We do this so that the binding is automatically
unbound even if the userspace process crashes.</p>
<p>Note that any reasonably well-behaved dmabuf from any exporter should work with
devmem TCP, even if the dmabuf is not actually backed by devmem. An example of
this is udmabuf, which wraps user memory (non-devmem) in a dmabuf.</p>
</section>
<section id="socket-setup">
<h3>Socket Setup<a class="headerlink" href="#socket-setup" title="Link to this heading">¶</a></h3>
<p>The socket must be flow steered to the dmabuf bound RX queue:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>ethtool -N eth1 flow-type tcp4 ... queue 15
</pre></div>
</div>
</section>
<section id="receiving-data">
<h3>Receiving data<a class="headerlink" href="#receiving-data" title="Link to this heading">¶</a></h3>
<p>The user application must signal to the kernel that it is capable of receiving
devmem data by passing the MSG_SOCK_DEVMEM flag to recvmsg:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>ret = recvmsg(fd, &amp;msg, MSG_SOCK_DEVMEM);
</pre></div>
</div>
<p>Applications that do not specify the MSG_SOCK_DEVMEM flag will receive an EFAULT
on devmem data.</p>
<p>Devmem data is received directly into the dmabuf bound to the NIC in ‘NIC
Setup’, and the kernel signals such to the user via the SCM_DEVMEM_* cmsgs:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>for (cm = CMSG_FIRSTHDR(&amp;msg); cm; cm = CMSG_NXTHDR(&amp;msg, cm)) {
        if (cm-&gt;cmsg_level != SOL_SOCKET ||
                (cm-&gt;cmsg_type != SCM_DEVMEM_DMABUF &amp;&amp;
                 cm-&gt;cmsg_type != SCM_DEVMEM_LINEAR))
                continue;

        dmabuf_cmsg = (struct dmabuf_cmsg *)CMSG_DATA(cm);

        if (cm-&gt;cmsg_type == SCM_DEVMEM_DMABUF) {
                /* Frag landed in dmabuf.
                 *
                 * dmabuf_cmsg-&gt;dmabuf_id is the dmabuf the
                 * frag landed on.
                 *
                 * dmabuf_cmsg-&gt;frag_offset is the offset into
                 * the dmabuf where the frag starts.
                 *
                 * dmabuf_cmsg-&gt;frag_size is the size of the
                 * frag.
                 *
                 * dmabuf_cmsg-&gt;frag_token is a token used to
                 * refer to this frag for later freeing.
                 */

                struct dmabuf_token token;
                token.token_start = dmabuf_cmsg-&gt;frag_token;
                token.token_count = 1;
                continue;
        }

        if (cm-&gt;cmsg_type == SCM_DEVMEM_LINEAR)
                /* Frag landed in linear buffer.
                 *
                 * dmabuf_cmsg-&gt;frag_size is the size of the
                 * frag.
                 */
                continue;

}
</pre></div>
</div>
<p>Applications may receive 2 cmsgs:</p>
<ul class="simple">
<li><p>SCM_DEVMEM_DMABUF: this indicates the fragment landed in the dmabuf indicated
by dmabuf_id.</p></li>
<li><p>SCM_DEVMEM_LINEAR: this indicates the fragment landed in the linear buffer.
This typically happens when the NIC is unable to split the packet at the
header boundary, such that part (or all) of the payload landed in host
memory.</p></li>
</ul>
<p>Applications may receive no SO_DEVMEM_* cmsgs. That indicates non-devmem,
regular TCP data that landed on an RX queue not bound to a dmabuf.</p>
</section>
<section id="freeing-frags">
<h3>Freeing frags<a class="headerlink" href="#freeing-frags" title="Link to this heading">¶</a></h3>
<p>Frags received via SCM_DEVMEM_DMABUF are pinned by the kernel while the user
processes the frag. The user must return the frag to the kernel via
SO_DEVMEM_DONTNEED:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>ret = setsockopt(client_fd, SOL_SOCKET, SO_DEVMEM_DONTNEED, &amp;token,
                 sizeof(token));
</pre></div>
</div>
<p>The user must ensure the tokens are returned to the kernel in a timely manner.
Failure to do so will exhaust the limited dmabuf that is bound to the RX queue
and will lead to packet drops.</p>
<p>The user must pass no more than 128 tokens, with no more than 1024 total frags
among the token-&gt;token_count across all the tokens. If the user provides more
than 1024 frags, the kernel will free up to 1024 frags and return early.</p>
<p>The kernel returns the number of actual frags freed. The number of frags freed
can be less than the tokens provided by the user in case of:</p>
<ol class="loweralpha simple">
<li><p>an internal kernel leak bug.</p></li>
<li><p>the user passed more than 1024 frags.</p></li>
</ol>
</section>
</section>
<section id="implementation-caveats">
<h2>Implementation &amp; Caveats<a class="headerlink" href="#implementation-caveats" title="Link to this heading">¶</a></h2>
<section id="unreadable-skbs">
<h3>Unreadable skbs<a class="headerlink" href="#unreadable-skbs" title="Link to this heading">¶</a></h3>
<p>Devmem payloads are inaccessible to the kernel processing the packets. This
results in a few quirks for payloads of devmem skbs:</p>
<ul class="simple">
<li><p>Loopback is not functional. Loopback relies on copying the payload, which is
not possible with devmem skbs.</p></li>
<li><p>Software checksum calculation fails.</p></li>
<li><p>TCP Dump and bpf can’t access devmem packet payloads.</p></li>
</ul>
</section>
</section>
<section id="testing">
<h2>Testing<a class="headerlink" href="#testing" title="Link to this heading">¶</a></h2>
<p>More realistic example code can be found in the kernel source under
<code class="docutils literal notranslate"><span class="pre">tools/testing/selftests/net/ncdevmem.c</span></code></p>
<p>ncdevmem is a devmem TCP netcat. It works very similarly to netcat, but
receives data directly into a udmabuf.</p>
<p>To run ncdevmem, you need to run it on a server on the machine under test, and
you need to run netcat on a peer to provide the TX data.</p>
<p>ncdevmem has a validation mode as well that expects a repeating pattern of
incoming data and validates it as such. For example, you can launch
ncdevmem on the server by:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>ncdevmem -s &lt;server IP&gt; -c &lt;client IP&gt; -f eth1 -d 3 -n 0000:06:00.0 -l \
         -p 5201 -v 7
</pre></div>
</div>
<p>On client side, use regular netcat to send TX data to ncdevmem process
on the server:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>yes $(echo -e \\x01\\x02\\x03\\x04\\x05\\x06) | \
        tr \\n \\0 | head -c 5G | nc &lt;server IP&gt; 5201 -p 5201
</pre></div>
</div>
</section>
</section>


          </div>
          
        </div>
      </div>
    <div class="clearer"></div>
  </div>
    <div class="footer">
      &copy;The kernel development community.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 7.2.6</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.12</a>
      
      |
      <a href="../_sources/networking/devmem.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>